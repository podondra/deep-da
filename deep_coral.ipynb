{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from qso import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coral(src_data, trg_data, device):\n",
    "    d = src_data.size(1)\n",
    "    n_src, n_trg = src_data.size(0), trg_data.size(0)\n",
    "    \n",
    "    src_cov = torch.ones((1, n_src)).to(device) @ src_data\n",
    "    src_cov = (\n",
    "        src_data.t() @ src_data - (src_cov.t() @ src_cov) / n_src\n",
    "    ) / (n_src - 1)\n",
    "    \n",
    "    trg_cov = torch.ones((1, n_trg)).to(device) @ trg_data\n",
    "    trg_cov = (\n",
    "        trg_data.t() @ trg_data - (trg_cov.t() @ trg_cov) / n_trg\n",
    "    ) / (n_trg - 1)\n",
    "    \n",
    "    return (src_cov - trg_cov).pow(2).sum() / (4 * d * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamost = h5py.File(dataset.LAMOST_DATASET, \"r\")\n",
    "sdss = h5py.File(dataset.SDSS_DATASET, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_set = dataset.HDF5Dataset(sdss[\"X_va\"], sdss[\"y_va\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].reshape(1, -1)\n",
    "\n",
    "\n",
    "trg_set = TargetDataset(lamost[\"X_va\"][...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_loader = DataLoader(src_set, batch_size=64, shuffle=True)\n",
    "trg_loader = DataLoader(trg_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCORAL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCORAL, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(32, 48, 5)\n",
    "        self.pool2 = nn.MaxPool1d(2, 2)\n",
    "        self.fc1 = nn.Linear(48 * 911, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "    \n",
    "    def features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def output(self, x):\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fetures(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv1d:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 1000\n",
    "writer = SummaryWriter(\"runs/deep_coral\")\n",
    "device = torch.device(\"cuda\")\n",
    "deep_coral = DeepCORAL().to(device)\n",
    "deep_coral.apply(init_weights)\n",
    "optimizer = optim.Adam(deep_coral.parameters())\n",
    "iterator = count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_coral.train()\n",
    "for i, (src_data, src_label), trg_data in zip(iterator, src_loader, trg_loader):\n",
    "    src_data, src_label = src_data.to(device), src_label.view(-1, 1).to(device)\n",
    "    trg_data = trg_data.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    src_features = deep_coral.features(src_data)\n",
    "    output = deep_coral.output(src_features)\n",
    "    trg_features = deep_coral.features(trg_data)\n",
    "    \n",
    "    loss_class = F.binary_cross_entropy_with_logits(output, src_label)\n",
    "    loss_coral = coral(src_features, trg_features, device)\n",
    "    loss = loss_class + LAMBDA * loss_coral\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    writer.add_scalar(\"loss/class\", loss_class, i)\n",
    "    writer.add_scalar(\"loss/coral\", LAMBDA * loss_coral, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
